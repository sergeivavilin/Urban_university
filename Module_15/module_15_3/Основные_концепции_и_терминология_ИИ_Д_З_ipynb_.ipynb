{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание\n",
        "\n",
        "Ознакомьтесь с приведёнными ниже примерами использования алгоритмов МО и НС для решения задачи распознавания рукописных цифр.\n",
        "\n",
        "## Порядок выполнения ДЗ\n",
        "\n",
        "1. Сделайте копию данного блокнота себе на диск. Далее работайте со своей копией блокнота. Сохраняйте вносимые в неё изменения.\n",
        "2. Ознакомьтесь с теоретическим текстом и кодом из настоящего блокнота.\n",
        "3. Перенесите примеры кода в отдельные кодовые ячейки и выполните их.\n",
        "4. Создайте тестовую ячейку, куда запишите ответы на теоретические вопросы.\n",
        "5. Расшарьте блокнот и используйте ссылку как ответ на ДЗ."
      ],
      "metadata": {
        "id": "SeivPBkJjNUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Учебный пример: Рещение задачи классификация рукописных цифр с использованием машинного обучения, глубокого обучения и нейронных сетей\n",
        "\n",
        "В этом задании мы будем использовать набор данных MNIST, который содержит изображения рукописных цифр (от 0 до 9). Мы реализуем три различных подхода к классификации этих изображений:\n",
        "\n",
        "1. **Машинное обучение**: Используем метод k-ближайших соседей (k-NN).\n",
        "2. **Глубокое обучение**: Используем многослойный перцептрон (MLP).\n",
        "3. **Нейронные сети**: Используем сверточную нейронную сеть (CNN).\n",
        "\n",
        "### Шаг 1: Установка библиотек\n",
        "\n",
        "Установите необходимые библиотеки:\n",
        "\n",
        "```bash\n",
        "pip install numpy pandas scikit-learn tensorflow keras\n",
        "```\n",
        "\n",
        "### Шаг 2: Загрузка и предобработка данных\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Загрузка данных MNIST\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X, y = mnist.data / 255.0, mnist.target.astype(int)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "```\n",
        "\n",
        "### Шаг 3: Алгоритм машинного обучения (k-NN)\n",
        "\n",
        "```python\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Создание и обучение модели k-NN\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Прогнозирование на тестовой выборке\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "\n",
        "print(f'Accuracy of k-NN: {accuracy_knn:.4f}')\n",
        "```\n",
        "\n",
        "### Шаг 4: Глубокое обучение (MLP)\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "# Предобработка меток для MLP\n",
        "y_train_mlp = to_categorical(y_train, 10)\n",
        "y_test_mlp = to_categorical(y_test, 10)\n",
        "\n",
        "# Создание модели MLP\n",
        "model_mlp = Sequential([\n",
        "    Flatten(input_shape=(784,)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Компиляция и обучение модели MLP\n",
        "model_mlp.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_mlp.fit(X_train, y_train_mlp, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Оценка модели на тестовой выборке\n",
        "loss_mlp, accuracy_mlp = model_mlp.evaluate(X_test, y_test_mlp)\n",
        "\n",
        "print(f'Accuracy of MLP: {accuracy_mlp:.4f}')\n",
        "```\n",
        "\n",
        "### Шаг 5: Нейронные сети (CNN)\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n",
        "\n",
        "# Предобработка данных для CNN\n",
        "X_train_cnn = X_train.values.reshape(-1, 28, 28, 1)\n",
        "X_test_cnn = X_test.values.reshape(-1, 28, 28, 1)\n",
        "y_train_cnn = to_categorical(y_train, 10)\n",
        "y_test_cnn = to_categorical(y_test, 10)\n",
        "\n",
        "# Создание модели CNN\n",
        "model_cnn = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Компиляция и обучение модели CNN\n",
        "model_cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_cnn.fit(X_train_cnn, y_train_cnn, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Оценка модели на тестовой выборке\n",
        "loss_cnn, accuracy_cnn = model_cnn.evaluate(X_test_cnn, y_test_cnn)\n",
        "\n",
        "print(f'Accuracy of CNN: {accuracy_cnn:.4f}')\n",
        "```\n",
        "\n",
        "### Заключение\n",
        "\n",
        "В этом задании мы реализовали три различных подхода к классификации изображений рукописных цифр с использованием средств машинного обучения (k-NN), глубокого обучения (MLP) и нейронных сетей (CNN). Мы увидели, что каждый из этих подходов имеет свои преимущества и недостатки, и что сложные модели глубокого обучения могут значительно улучшить точность классификации по сравнению с простыми моделями машинного обучения.\n",
        "\n",
        "### Теоритические вопросы\n",
        "\n",
        "1. Какие преимущества и недостатки использованных методов вы увидели?\n",
        "2. В чем, на ваш взгляд, заключается принципиальная разница между многослойным перцептроном и сверточной нейронной сетью?\n",
        "3. Какие методы предобработки данных были использованы в этом задании?\n"
      ],
      "metadata": {
        "id": "vGMR-kTge1Wr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDsO7Qm5e0px"
      },
      "outputs": [],
      "source": [
        "#Создайте необходимое количество кодовых ячеек и исполните в них приведенный выше код"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Выполнение ДЗ:\n",
        "\n",
        "---\n",
        "\n",
        "# **1. Установим необходимые библиотеки:**"
      ],
      "metadata": {
        "id": "CQtZxpl0fztl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy pandas scikit-learn tensorflow keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD5zO414fo0K",
        "outputId": "3ed3f212-0135-49f1-d09c-e3e368141aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.2)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Загрузка и предобработка данных:**"
      ],
      "metadata": {
        "id": "h3DqTpQBga4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Загрузка данных MNIST\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X, y = mnist.data / 255.0, mnist.target.astype(int)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "L79BJX0OgktQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**3. Алгоритм машинного обучения (k-NN)**"
      ],
      "metadata": {
        "id": "IYGDjDF5g9BP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Создание и обучение модели k-NN\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Прогнозирование на тестовой выборке\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "\n",
        "print(f'Accuracy of k-NN: {accuracy_knn:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-imyjBhohSBC",
        "outputId": "583861bd-e3f0-4dba-d6df-3eb238b004c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of k-NN: 0.9713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Глубокое обучение (MLP)**"
      ],
      "metadata": {
        "id": "d9lcBfYxhttI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "# Предобработка меток для MLP\n",
        "y_train_mlp = to_categorical(y_train, 10)\n",
        "y_test_mlp = to_categorical(y_test, 10)\n",
        "\n",
        "# Создание модели MLP\n",
        "model_mlp = Sequential([\n",
        "    Flatten(input_shape=(784,)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Компиляция и обучение модели MLP\n",
        "model_mlp.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_mlp.fit(X_train, y_train_mlp, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Оценка модели на тестовой выборке\n",
        "loss_mlp, accuracy_mlp = model_mlp.evaluate(X_test, y_test_mlp)\n",
        "\n",
        "print(f'Accuracy of MLP: {accuracy_mlp:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YXPR52ph0Qn",
        "outputId": "938541ba-bc18-46f3-d9f9-89f8e594a798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8580 - loss: 0.4861 - val_accuracy: 0.9583 - val_loss: 0.1340\n",
            "Epoch 2/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9664 - loss: 0.1107 - val_accuracy: 0.9679 - val_loss: 0.1053\n",
            "Epoch 3/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9793 - loss: 0.0697 - val_accuracy: 0.9712 - val_loss: 0.0939\n",
            "Epoch 4/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9834 - loss: 0.0523 - val_accuracy: 0.9679 - val_loss: 0.1073\n",
            "Epoch 5/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9868 - loss: 0.0417 - val_accuracy: 0.9718 - val_loss: 0.0973\n",
            "Epoch 6/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9902 - loss: 0.0308 - val_accuracy: 0.9722 - val_loss: 0.0984\n",
            "Epoch 7/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9919 - loss: 0.0233 - val_accuracy: 0.9721 - val_loss: 0.0999\n",
            "Epoch 8/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0212 - val_accuracy: 0.9721 - val_loss: 0.1069\n",
            "Epoch 9/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9938 - loss: 0.0186 - val_accuracy: 0.9745 - val_loss: 0.1076\n",
            "Epoch 10/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0145 - val_accuracy: 0.9737 - val_loss: 0.1051\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9727 - loss: 0.1064\n",
            "Accuracy of MLP: 0.9731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Нейронные сети (CNN)**"
      ],
      "metadata": {
        "id": "1gTUC-f_iEO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n",
        "\n",
        "# Предобработка данных для CNN\n",
        "X_train_cnn = X_train.values.reshape(-1, 28, 28, 1)\n",
        "X_test_cnn = X_test.values.reshape(-1, 28, 28, 1)\n",
        "y_train_cnn = to_categorical(y_train, 10)\n",
        "y_test_cnn = to_categorical(y_test, 10)\n",
        "\n",
        "# Создание модели CNN\n",
        "model_cnn = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Компиляция и обучение модели CNN\n",
        "model_cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_cnn.fit(X_train_cnn, y_train_cnn, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Оценка модели на тестовой выборке\n",
        "loss_cnn, accuracy_cnn = model_cnn.evaluate(X_test_cnn, y_test_cnn)\n",
        "\n",
        "print(f'Accuracy of CNN: {accuracy_cnn:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV_u54U4i8rh",
        "outputId": "d4b2867b-96ff-4ec9-cd1f-54f31ab80234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 37ms/step - accuracy: 0.8259 - loss: 0.5354 - val_accuracy: 0.9798 - val_loss: 0.0659\n",
            "Epoch 2/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 37ms/step - accuracy: 0.9644 - loss: 0.1153 - val_accuracy: 0.9849 - val_loss: 0.0480\n",
            "Epoch 3/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 37ms/step - accuracy: 0.9754 - loss: 0.0843 - val_accuracy: 0.9863 - val_loss: 0.0442\n",
            "Epoch 4/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 36ms/step - accuracy: 0.9791 - loss: 0.0716 - val_accuracy: 0.9882 - val_loss: 0.0357\n",
            "Epoch 5/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 36ms/step - accuracy: 0.9796 - loss: 0.0664 - val_accuracy: 0.9896 - val_loss: 0.0329\n",
            "Epoch 6/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 36ms/step - accuracy: 0.9850 - loss: 0.0496 - val_accuracy: 0.9877 - val_loss: 0.0395\n",
            "Epoch 7/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 36ms/step - accuracy: 0.9841 - loss: 0.0523 - val_accuracy: 0.9894 - val_loss: 0.0363\n",
            "Epoch 8/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 37ms/step - accuracy: 0.9863 - loss: 0.0428 - val_accuracy: 0.9895 - val_loss: 0.0354\n",
            "Epoch 9/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 36ms/step - accuracy: 0.9861 - loss: 0.0449 - val_accuracy: 0.9896 - val_loss: 0.0381\n",
            "Epoch 10/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 36ms/step - accuracy: 0.9874 - loss: 0.0388 - val_accuracy: 0.9912 - val_loss: 0.0327\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9892 - loss: 0.0338\n",
            "Accuracy of CNN: 0.9900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Выводы:**\n",
        "\n",
        "**Теоретические вопросы:**\n",
        "\n",
        "`1.Какие преимущества и недостатки использованных методов вы увидели?`\n",
        "\n",
        "Для классификации изображений рукописного ввода используем несколько подходов\n",
        "\n",
        "Машинное обучение: Используем метод k-ближайших соседей (k-NN).\n",
        "Глубокое обучение: Используем многослойный перцептрон (MLP).\n",
        "Нейронные сети: Используем сверточную нейронную сеть (CNN).\n",
        "Каждый из способов показывает хороший результат точности, но у каждого есть свои плюсы и минусы.\n",
        "\n",
        "Метод k-ближайших соседей (k-NN)\n",
        "\n",
        "Плюсы: Алгоритм прост, легко реализуем и имеет достаточную точность для проверки гипотез. Алгоритм универсален - его можно использовать для задач классификации и регрессии. Не чувствителен к выбросам данных. Быстро работает на небольшом объеме данных\n",
        "\n",
        "Минусы: Алгоритм работает значительно медленнее при увеличении объема данных. Всегда нужно определять оптимальное значение k. Имеет точность ниже чем у других методов\n",
        "\n",
        "Многослойный перцептрон (MLP)\n",
        "\n",
        "Плюсы: Небольшое количество скрытых слоев. Короткое время обучения по сравнению со сверточными сетями. Работает на обычных графических устройствах. Имеют бОльшую точность по сравнению с методом k-ближайших соседей.\n",
        "\n",
        "Минусы: Низкая скорость обучения по сравнению с методом k-ближайших соседей. Необходимость выбирать структуру сети под конкретную задачу. Чувствителен к масштабированию функций, поэтому настоятельно рекомендуется масштабировать данные\n",
        "\n",
        "Cверточная нейронная сеть (СNN)\n",
        "\n",
        "Плюсы: Хорошо справляются с огромными наборами данных и эффективно обучаются на графических процессорах за счёт параллельных вычислений. Могут обучаться с помощью различных методов для достижения лучших результатов точности. Могут решать задачи различного характера. Имеют более высокие показатели точности.\n",
        "\n",
        "Минусы: Продолжительное время обучения (несколько дней и более) для нейронной сети с числом слоёв свёртки свыше двух. Большая вероятность переобучения сети при недостаточном количестве примеров при обучении с учителем. Слишком много варьируемых параметров сети, которые подбираются эмпирическим путем для каждой новой задачи\\"
      ],
      "metadata": {
        "id": "Rujsc_l7UFBP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "sSfIEY1PUOjn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`2.В чем, на ваш взгляд, заключается принципиальная разница между многослойным перцептроном и сверточной нейронной сетью?`**\n",
        "\n",
        "Основным отличием многослойного прецептрона(MLP) от сверточных нейронных сетей(CNN) является продолжительность и сложность обучения. Также у них разная архитектура нейроных слоев. Каждый нейрон в MLP принимает на вход все значения из предыдущего слоя и вычисляет свой выход с использованием активационной функции. Таким образом, сеть может обрабатывать данные в виде плоского вектора. CNN используют свертку (convolution) для извлечения признаков из входных данных.\n",
        "У MLP данные обрабатываются целиком, у CNN фрагментами. Каждый узел MLP напрямую связан с последующим, в отличии от CNN, которая использует не индивидуальные веса, а разделённые веса - матрицы весов небольшого размера\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "yihaE8jVn-9B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`3.Какие методы предобработки данных были использованы в этом задании?`**\n",
        "\n",
        "В приведенном коде используется несколько методов предобработки данных.\n",
        "\n",
        "1.Нормализация данных:\n",
        "\n",
        "X, y = mnist.data / 255.0, mnist.target.astype(int)\n",
        "\n",
        "Здесь данные нормализуются путём деления каждого пикселя изображения на 255, чтобы привести значения пикселей в диапазон от 0 до 1. Это часто используется для улучшения работы моделей машинного обучения, так как уменьшает разброс данных и ускоряет процесс обучения.\n",
        "Также метки классов (целевые переменные y) преобразуются в целые числа с помощью astype(int), поскольку изначально они могли быть строковыми значениями.\n",
        "\n",
        "2.Разделение данных на обучающую и тестовую выборки:\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "Здесь используется метод train_test_split для разделения данных на обучающий набор (X_train, y_train) и тестовый набор (X_test, y_test). Аргумент test_size=0.2 означает, что 20% данных используются для тестирования, а 80% — для обучения.\n",
        "random_state=42 обеспечивает воспроизводимость результата"
      ],
      "metadata": {
        "id": "GopxIizEVcM9"
      }
    }
  ]
}