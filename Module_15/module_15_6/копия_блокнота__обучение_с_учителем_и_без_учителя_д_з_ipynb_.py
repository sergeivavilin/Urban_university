# -*- coding: utf-8 -*-
"""Копия блокнота "Обучение с учителем и без учителя. Д.З.ipynb"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C_G5drEw5xD0UG-IGOTZWZYi8FeJqJsr

#Домашнее задание: Обучение с учителем и без учителя. Д.З

Обучение с учителем (supervised learning) и без учителя (unsupervised learning) — две основные парадигмы машинного обучения, которые используются для решения различных задач.

### Обучение с учителем (Supervised Learning)
Обучение с учителем включает в себя обучение модели на размеченных данных. Размеченные данные означают, что для каждого примера в наборе данных известен правильный ответ или метка.

#### Примеры задач обучения с учителем:
1. **Классификация**: Предсказание категории или класса, к которому принадлежит объект.
   - Пример: Распознавание изображений (определить, что изображено на картинке: кошка или собака).
2. **Регрессия**: Предсказание непрерывного значения.
   - Пример: Прогнозирование цен на недвижимость.

#### Основные этапы обучения с учителем:
1. **Сбор и разметка данных**: Подготовка набора данных, где каждый пример имеет метку.
2. **Разделение данных**: Деление набора данных на обучающую и тестовую части.
3. **Выбор модели**: Определение алгоритма, который будет использоваться для обучения (например, линейная регрессия, дерево решений).
4. **Обучение модели**: Использование обучающего набора данных для настройки параметров модели.
5. **Оценка модели**: Проверка качества модели на тестовом наборе данных.

### Обучение без учителя (Unsupervised Learning)
Обучение без учителя включает в себя обучение модели на неразмеченных данных. Модель должна самостоятельно выявить структуру или паттерны в данных.

#### Примеры задач обучения без учителя:
1. **Кластеризация**: Группировка объектов в кластеры на основе их сходства.
   - Пример: Сегментация клиентов по схожести их покупательских привычек.
2. **Поиск ассоциаций**: Выявление правил ассоциаций между объектами в данных.
   - Пример: Анализ рыночной корзины (какие продукты часто покупаются вместе).

#### Основные этапы обучения без учителя:
1. **Сбор данных**: Подготовка набора данных без меток.
2. **Выбор алгоритма**: Определение алгоритма, который будет использоваться для обучения (например, k-means, алгоритм ассоциации).
3. **Обучение модели**: Применение алгоритма к данным для выявления структур или паттернов.
4. **Интерпретация результатов**: Анализ полученных результатов и их интерпретация.

### Домашнее задание
Создайте копию блокнота. Далее выполнйте задания в ней.

1. **Теоретическая часть**:
   - Опишите различия между обучением с учителем и без учителя.
   - Приведите примеры задач, которые решаются с помощью обучения с учителем, и задачи, которые решаются с помощью обучения без учителя.

2. **Практическая часть**:
   - Найдите датасет, который можно использовать для обучения с учителем и без учителя. (Например, датасет "Wine" из библиотеки Scikit-Learn. Этот датасет содержит информацию о химическом составе различных вин и их классах (три разных сорта вина)).
   - Реализуйте  алгоритм обучения с учителем и без учителя. Интерпретируйте результаты.

```python
# Импортируем необходимые библиотеки
import numpy as np
from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
```
Ссылку на ваш блокнот разместите в домашнем задании.

Удачи в выполнении задания! Если возникнут вопросы, не стесняйтесь обращаться за помощью.

### Обучение с учителем: Классификация с использованием логистической регрессии
Используем датасет "Iris" для классификации видов ирисов.
"""

# Импортируем необходимые библиотеки
import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Загружаем датасет Iris
iris = load_iris()
X = iris.data
y = iris.target

# Разделяем данные на обучающую и тестовую части
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Обучаем модель логистической регрессии
model = LogisticRegression(max_iter=200)
model.fit(X_train, y_train)

# Предсказываем результаты на тестовых данных
y_pred = model.predict(X_test)

# Оцениваем качество модели
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
print("Classification Report:")
print(classification_report(y_test, y_pred))

"""##Пояснение к метрикам
###Accuracy:

**accuracy**: Доля правильно предсказанных классов среди всех предсказаний. В данном случае, accuracy равна 1.00 (или 100%), что означает, что модель правильно предсказала все 45 примеров.

###Macro Avg:

**macro** avg: Среднее арифметическое значения precision, recall и F1-score по всем классам. В данном случае все значения равны 1.00, что указывает на идеальную модель для всех классов.
precision: Доля правильно предсказанных положительных результатов среди всех предсказанных положительных результатов.
recall: Доля правильно предсказанных положительных результатов среди всех фактических положительных результатов.
f1-score: Среднее гармоническое значение precision и recall, что позволяет учесть оба этих параметра.


###Weighted Avg:

**weighted avg**: Взвешенное среднее значение precision, recall и F1-score по всем классам, где вес каждого класса пропорционален количеству истинных примеров этого класса. В данном случае все значения равны 1.00, что также указывает на идеальную модель.
Взвешенное среднее полезно, когда классы неравномерно распределены, так как оно учитывает количество примеров каждого класса.

### Обучение без учителя: Кластеризация с использованием алгоритма K-means
Используем тот же датасет "Iris" для кластеризации.
"""

# Импортируем необходимые библиотеки
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Обучаем модель K-means
kmeans = KMeans(n_clusters=3, random_state=42)
kmeans.fit(X)

# Предсказываем кластеры
clusters = kmeans.predict(X)

# Визуализируем результаты кластеризации
plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis', marker='o')
plt.title('K-means Clustering of Iris Dataset')
plt.xlabel('Sepal Length')
plt.ylabel('Sepal Width')
plt.show()

"""### Пояснение коду
1. **Обучение с учителем (Supervised Learning)**:
   - Загружаем датасет Iris.
   - Разделяем данные на обучающую и тестовую выборки.
   - Обучаем модель логистической регрессии на обучающей выборке.
   - Оцениваем модель на тестовой выборке, выводим точность и отчёт классификации.

2. **Обучение без учителя (Unsupervised Learning)**:
   - Загружаем датасет Iris.
   - Обучаем модель K-means для кластеризации данных.
   - Визуализируем результаты кластеризации, отображая кластеры на графике.

---

# Теоритическое задание

Обучение с учителем (supervised learning) и без учителя (unsupervised learning) — две основные парадигмы машинного обучения, которые используются для решения различных задач.

### Обучение с учителем (Supervised Learning)
Обучение с учителем включает в себя обучение модели на размеченных данных. Размеченные данные означают, что для каждого примера в наборе данных известен правильный ответ или метка.

#### Примеры задач обучения с учителем:
1. **Классификация**: Предсказание категории или класса, к которому принадлежит объект.
   - Пример: Распознавание изображений (определить, что изображено на картинке: кошка или собака).
2. **Регрессия**: Предсказание непрерывного значения.
   - Пример: Прогнозирование цен на недвижимость.

#### Основные этапы обучения с учителем:
1. **Сбор и разметка данных**: Подготовка набора данных, где каждый пример имеет метку.
2. **Разделение данных**: Деление набора данных на обучающую и тестовую части.
3. **Выбор модели**: Определение алгоритма, который будет использоваться для обучения (например, линейная регрессия, дерево решений).
4. **Обучение модели**: Использование обучающего набора данных для настройки параметров модели.
5. **Оценка модели**: Проверка качества модели на тестовом наборе данных.

### Обучение без учителя (Unsupervised Learning)
Обучение без учителя включает в себя обучение модели на неразмеченных данных. Модель должна самостоятельно выявить структуру или паттерны в данных.

#### Примеры задач обучения без учителя:
1. **Кластеризация**: Группировка объектов в кластеры на основе их сходства.
   - Пример: Сегментация клиентов по схожести их покупательских привычек.
2. **Поиск ассоциаций**: Выявление правил ассоциаций между объектами в данных.
   - Пример: Анализ рыночной корзины (какие продукты часто покупаются вместе).

#### Основные этапы обучения без учителя:
1. **Сбор данных**: Подготовка набора данных без меток.
2. **Выбор алгоритма**: Определение алгоритма, который будет использоваться для обучения (например, k-means, алгоритм ассоциации).
3. **Обучение модели**: Применение алгоритма к данным для выявления структур или паттернов.
4. **Интерпретация результатов**: Анализ полученных результатов и их интерпретация.

#### Основные различия.

\begin{array}{|c|c|} \hline
 & 	Обучение\ с\ учителем & Обучение\ без\ учителя \\ \hline
Разметка\ данных & Данные\ размечены\ для\ всех\ обучающих\ примеров & Данные\ не\ размечены  \\ \hline
Цель & Прогнозирование\ или\ классифицирование & Выявить\ скрытую\ структуру\ или\ группировку\ данных  \\\hline
Примеры\ алгоритмов & Логистическая\ регрессия,\ SVM,\ KNN,\ Деревья\ решений & K-Means,\ Иерархическая\ кластеризация,\ PCA  \\ \hline
Типы\ задач & Классификация,\ Регрессия & Кластеризация,\ Понижение\ размерности\\ \hline
\end{array}

####Ключевая разница в подходе

В обучении с учителем модель строится с целью предсказания, в то время как в обучении без учителя акцент делается на поиске скрытых закономерностей в данных.

# Практическое задание

В ходе выполнения ДЗ используем датасет `Wine` из библиотеки `sklearn`\
Для обучения с учителем будем использовать метод Логистической регрессии, а для
обучения без учителя - K-Means

### 1. Загрузка и подготовка данных
"""

# Импортируем необходимые библиотеки
import numpy as np
from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt


# Загрузка датасета Wine
wine_data = load_wine()
X = wine_data.data  # признаки
y = wine_data.target  # классы вин

"""### 2. Обучение с учителем: Логистическая регрессия"""

# Разделение на обучающую и тестовую выборки для задачи с учителем
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Создание и обучение модели логистической регрессии
# Максимальная точность достигается при max_iter = 396
logreg_model = LogisticRegression(max_iter=3202)  # Увеличиваем max_iter для исключения ConvergenceWarning,
logreg_model.fit(X_train, y_train)

# Прогнозирование на тестовых данных
y_pred = logreg_model.predict(X_test)

# Оцениваем качество модели
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
print("Classification Report:", classification_report(y_test, y_pred))

"""### 3. Обучение без учителя: Кластеризация с K-Means"""

# Создание и обучение модели KMeans с явным указанием n_init
# Количество кластеров выбираем 3, если количество кластеров не известно лучше использовать метод локтя
kmeans = KMeans(n_clusters=3, n_init = 10, random_state=42)
kmeans.fit(X)

# Получение центров кластеров и меток
cluster_centers = kmeans.cluster_centers_
labels = kmeans.labels_

print("Cluster centers:", cluster_centers)
print("Labels:", labels)


# Отображение точек данных с цветом в зависимости от меток кластеров
colors = ['blue', 'green', 'yellow']
for i in range(len(X)):
    plt.scatter(X[i][0], X[i][1], color=colors[labels[i]], s=100)

# Отображение центров кластеров
plt.scatter(
    cluster_centers[:, 0],
    cluster_centers[:, 1],
    color='red',
    marker='X',
    s=200,
    label='Cluster Centers'
    )

plt.xlabel('X values')
plt.ylabel('Y values')
plt.title('KMeans Clustering')
plt.legend()
plt.show()

"""
## Интерпретация результатов

### Для алгоритма логистической регрессии (обучение с учителем)
- **Аccuracy** показывает долю правильно классифицированных объектов в модели. Например, если accuracy_score равен 0.8, это означает, что модель правильно классифицировала 80% объектов.
- **Classification Report** включает метрики точности, полноты и F1-score, которые дают представление о качестве классификации для каждого класса.

### Для алгоритма K-Means (обучение без учителя)
- **Распределение по цветам** позволяют увидеть, как K-Means распределил объекты по группам.
- **Cluster Centers** представляют собой средние значения признаков всех точек, относящихся к каждому кластеру. Описывает средние характеристики (или "типичный" объект) для каждого кластера

### Сравнение

- **Обучение с учителем**:
  - Используется, когда есть размеченные данные или данные можно разметить с приемлемыми трудозатратами.
  - Применяется для задач классификации и регрессии.
  - Требует наличия большого количества размеченных данных для обучения.

- **Обучение без учителя**:
  - Используется, когда размеченные данные отсутствуют.
  - Применяется для задач кластеризации, выявления аномалий и снижения размерности.
  - Полезно для выявления скрытых структур и шаблонов в данных.

Оба подхода дают разные перспективы на данные. Логистическая регрессия находит границы между тремя сортами вин, а K-Means помогает разделить данные на группы, что полезно для анализа, если истинные метки классов недоступны."""