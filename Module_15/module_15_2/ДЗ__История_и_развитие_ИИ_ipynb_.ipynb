{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Домашнее задание"
      ],
      "metadata": {
        "id": "RKVH7ZaAezCN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## История и развитие искусственного интеллекта (ИИ)\n",
        "\n",
        "### Введение\n",
        "\n",
        "Искусственный интеллект (ИИ) — это область компьютерных наук, посвящённая созданию систем, способных выполнять задачи, которые требуют человеческого интеллекта. Сюда входят такие задачи, как распознавание речи, принятие решений, перевод текстов и распознавание изображений.\n",
        "\n",
        "### История развития ИИ\n",
        "\n",
        "1. **Ранние исследования (1950-е годы):**\n",
        "   - **1950:** Алан Тьюринг предложил тест Тьюринга, как критерий для определения интеллекта машины.\n",
        "   - **1956:** В Дартмуте состоялась первая конференция по ИИ, которая считается началом формального развития этой области.\n",
        "\n",
        "2. **Золотой век ИИ (1960-1970-е годы):**\n",
        "   - В этот период были разработаны первые программы ИИ, такие как логические теоремы и системы, основанные на правилах.\n",
        "   - **1966:** Проект ELIZA Джозефа Вейценбаума — первая программа, которая имитировала общение на естественном языке.\n",
        "\n",
        "3. **Зима ИИ (1970-1980-е годы):**\n",
        "   - Период упадка интереса и финансирования в области ИИ, вызванный разочарованием в результатах исследований и ограничениями вычислительных мощностей.\n",
        "\n",
        "4. **Возрождение ИИ (1990-е годы):**\n",
        "   - Возрождение интереса к ИИ благодаря успехам в области машинного обучения и увеличению вычислительных мощностей.\n",
        "   - **1997:** Компьютер Deep Blue от IBM победил чемпиона мира по шахматам Гарри Каспарова.\n",
        "\n",
        "5. **Современный ИИ (2000-е годы — настоящее время):**\n",
        "   - Бурное развитие глубокого обучения и нейронных сетей благодаря большим данным (Big Data) и мощным графическим процессорам (GPU).\n",
        "   - **2012:** Прорыв в распознавании изображений с использованием сверточных нейронных сетей (CNN) в конкурсе ImageNet.\n",
        "\n",
        "### Однослойный и многослойный перцептрон\n",
        "\n",
        "Перцептрон — это простейшая форма искусственной нейронной сети, предложенная Фрэнком Розенблаттом в 1957 году. Перцептрон используется для задач классификации.\n",
        "\n",
        "#### Однослойный перцептрон\n",
        "\n",
        "Однослойный перцептрон состоит из одного слоя нейронов и может решать только линейно разделимые задачи.\n",
        "\n",
        "#### Пример кода однослойного перцептрона на Python\n"
      ],
      "metadata": {
        "id": "g_DiXNsZd6xV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Функция активации (шаговая функция)\n",
        "def step_function(x):\n",
        "    return np.where(x >= 0, 1, 0)\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size, learning_rate=0.01, epochs=1000):\n",
        "        self.W = np.zeros(input_size + 1)\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def predict(self, x):\n",
        "        return step_function(np.dot(self.W, x))\n",
        "\n",
        "    def train(self, X, y):\n",
        "        for _ in range(self.epochs):\n",
        "            for xi, target in zip(X, y):\n",
        "                xi = np.insert(xi, 0, 1)  # Вставка смещения (bias)\n",
        "                prediction = self.predict(xi)\n",
        "                self.W += self.learning_rate * (target - prediction) * xi\n",
        "\n",
        "# Данные для обучения (И, ИЛИ)\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([0, 0, 0, 1])  # Операция И (AND)\n",
        "\n",
        "perceptron = Perceptron(input_size=2)\n",
        "perceptron.train(X, y)\n",
        "\n",
        "# Тестирование\n",
        "for xi in X:\n",
        "    xi_with_bias = np.insert(xi, 0, 1)  # Вставка смещения (bias) для тестирования\n",
        "    print(f\"{xi} -> {perceptron.predict(xi_with_bias)}\")\n"
      ],
      "metadata": {
        "id": "tkmzaZNweCqa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcabf695-0c22-47a0-beb3-c8cedbd91b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0] -> 0\n",
            "[0 1] -> 0\n",
            "[1 0] -> 0\n",
            "[1 1] -> 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Многослойный перцептрон (MLP)\n",
        "\n",
        "Многослойный перцептрон состоит из нескольких слоев нейронов и способен решать нелинейные задачи. Он включает входной слой, один или несколько скрытых слоев и выходной слой."
      ],
      "metadata": {
        "id": "6M6YbJnldu4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Пример кода многослойного перцептрона на Python с использованием библиотеки `scikit-learn`"
      ],
      "metadata": {
        "id": "7sCs1ZV6blAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Данные для обучения (И, ИЛИ)\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([0, 0, 0, 1])  # Операция И (AND)\n",
        "\n",
        "# Создание и обучение MLP-классификатора\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(5,), activation='relu', max_iter=400, learning_rate_init=0.01, solver='adam')\n",
        "mlp.fit(X, y)\n",
        "\n",
        "# Тестирование\n",
        "for xi in X:\n",
        "    print(f\"{xi} -> {mlp.predict([xi])[0]}\")"
      ],
      "metadata": {
        "id": "Y4aS-x02cPp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание\n",
        "\n",
        "Многослойный перцептрон (MLP) может решать задачи, которые однослойный перцептрон не способен решить, из-за своей способности моделировать нелинейные зависимости. Одним из классических примеров такой задачи является проблема \"исключающее ИЛИ\" (XOR).\n",
        "\n",
        "### Проблема XOR\n",
        "\n",
        "Логическая операция XOR возвращает истину только в том случае, если один из входов истинный, а другой ложный. Ниже приведена таблица истинности для XOR:\n",
        "\n",
        "| Вход 1 | Вход 2 | XOR |\n",
        "|--------|--------|-----|\n",
        "|   0    |   0    |  0  |\n",
        "|   0    |   1    |  1  |\n",
        "|   1    |   0    |  1  |\n",
        "|   1    |   1    |  0  |\n",
        "\n",
        "Эту задачу нельзя решить с помощью однослойного перцептрона, так как она не является линейно разделимой. Однако многослойный перцептрон, содержащий хотя бы один скрытый слой, способен решить эту задачу.\n",
        "\n",
        "\n",
        "Ниже приведен код решения задачи XOR **многослойным** персептроном.\n",
        "\n",
        "Разберите ее самостоятельно.\n",
        "\n",
        "После чего создайте новую кодовую ячейку. Скопируйте в нее код **однослойного** персептрона и попытайтесь решить задачу на 10 000, 20 000, 50 000 эпохах.\n",
        "\n",
        "Создайте текстовую ячейку и напишите в ней свои выводы об однослойных и многослойных персептронах.\n",
        "\n",
        "Сохраните колаб и пришлите на него ссылку преподавателю.\n"
      ],
      "metadata": {
        "id": "w6HGKktpbujp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DahpZ9PqbFEF"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Данные для обучения (XOR)\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([0, 1, 1, 0])  # Операция XOR\n",
        "\n",
        "# Создание и обучение MLP-классификатора\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(5,), activation='relu', max_iter=5000, solver='adam')\n",
        "mlp.fit(X, y)\n",
        "\n",
        "# Тестирование\n",
        "for xi in X:\n",
        "    print(f\"{xi} -> {mlp.predict([xi])[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Скопируйте в код однослойного персептрона и попытайтесь решить задачу XOR на 10 000, 20 000, 50 000 эпохах.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Функция активации (шаговая функция)\n",
        "def step_function(x):\n",
        "    return np.where(x >= 0, 1, 0)\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size, learning_rate=0.01, epochs=1000):\n",
        "        self.W = np.zeros(input_size + 1)\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def predict(self, x):\n",
        "        return step_function(np.dot(self.W, x))\n",
        "\n",
        "    def train(self, X, y):\n",
        "        for _ in range(self.epochs):\n",
        "            for xi, target in zip(X, y):\n",
        "                xi = np.insert(xi, 0, 1)  # Вставка смещения (bias)\n",
        "                prediction = self.predict(xi)\n",
        "                self.W += self.learning_rate * (target - prediction) * xi\n",
        "\n",
        "# Данные для XOR\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_xor = np.array([0, 1, 1, 0])  # Ожидаемые результаты для XOR\n",
        "\n",
        "# Теперь создадим два перцептрона, которые будут разделять данные\n",
        "perceptron1 = Perceptron(input_size=2)\n",
        "perceptron2 = Perceptron(input_size=2)\n",
        "\n",
        "# Обучающие цели для каждого перцептрона:\n",
        "# Первый перцептрон обучается такой цели, которая напоминает операцию ИЛИ\n",
        "y1 = np.array([0, 1, 1, 1])  # Логика ИЛИ\n",
        "# Второй перцептрон обучается другой цели, которая напоминает операцию И\n",
        "y2 = np.array([0, 0, 0, 1])  # Логика И\n",
        "\n",
        "# Обучаем оба перцептрона\n",
        "perceptron1.train(X, y1)\n",
        "perceptron2.train(X, y2)\n",
        "\n",
        "\n",
        "# Финальное решение для XOR:\n",
        "# [0, 1, 1, 1] - [0, 0, 0, 1] = [0, 1, 1, 0]\n",
        "def xor_result(x):\n",
        "    # XOR логика: ИЛИ (output1) - И (output2)\n",
        "    return perceptron1.predict(x) - perceptron2.predict(x)\n",
        "\n",
        "# Тестирование\n",
        "for xi in X:\n",
        "    xi_with_bias = np.insert(xi, 0, 1)  # Вставка смещения (bias) для тестирования\n",
        "    print(f\"{xi} -> {xor_result(xi_with_bias)}\")"
      ],
      "metadata": {
        "id": "Du6zENjXkRvb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "609e8ae4-62a4-4294-f119-8be069c18e2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0] -> 0\n",
            "[0 1] -> 1\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Выводы:\n",
        "\n",
        "Однослойный перцептрон подходит только для линейно разделимых задач (задача \"И\" / \"ИЛИ\"). И это не зависит от количества циклов обучения(эпох).\n",
        "Для решения задачи исключаещего \"ИЛИ\" в решение предидущей задачи необходимо добавить второй перцептрон, который сможет решать похожую задачу. Один однослойный перцептрон будет решать задачу \"ИЛИ\", второй - задачу \"И\".\n",
        "Комбинация из нескольких однослойных пецептронов образует Многослойный перцептрон (MLP), который в свою очередь может решать нелинейные задачи."
      ],
      "metadata": {
        "id": "I3vxuNQsSdM1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ITdWBxUTmnp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}